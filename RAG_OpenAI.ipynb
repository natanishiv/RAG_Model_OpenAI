{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Creating **Embeddings**"
      ],
      "metadata": {
        "id": "XfRUc5QZEr7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install OpenAI==1.10.0"
      ],
      "metadata": {
        "id": "b_0ibqwpLBlo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pinecone-client==3.0.2"
      ],
      "metadata": {
        "id": "XixNWJ3NMEf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client=OpenAI(\n",
        "    api_key=\"\"                      #Enter your api key here\n",
        ")\n",
        "MODEL = \"text-embedding-3-large\""
      ],
      "metadata": {
        "id": "uKWYY1hkEqdk"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ASsuming dataset is in form of question answer pairs\n",
        "dataset=[\n",
        "    (\"Tell me something about Yardstick AI\",\"At Yardstick, we possess profound expertise in AI model integrations, fine-tuning, advanced analytics, image generations, speech AI, video generations using AI, chatbot frameworks and solutions\"),\n",
        "    (\"Where is Yardstick AI headquartered ?\",\"Bengaluru, India\"),\n",
        "    (\"How can I contact you ?\",\"contact@yardstick.live\")\n",
        "]\n",
        "\n"
      ],
      "metadata": {
        "id": "zU4qCoo-EnFQ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings={}\n",
        "for question,answer in dataset:\n",
        "\n",
        "  res=client.embeddings.create(\n",
        "      input=[question],\n",
        "      model=MODEL\n",
        "  )\n",
        "\n",
        "  question_embedding = res.data[0].embedding\n",
        "  embeddings[question] = {question_embedding}\n"
      ],
      "metadata": {
        "id": "OVsBq7XyGtXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mWn4xPaeKkSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Intializing Pinecone Index**"
      ],
      "metadata": {
        "id": "ZEXxNNUQKwAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from pinecone import Pinecone\n",
        "from pinecone import ServerlessSpec\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "a9pRIDHEN_-c"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pc = Pinecone(api_key=\"\")\n",
        "\n",
        "spec = ServerlessSpec(cloud=\"aws\", region=\"ap-south-1\")\n",
        "\n",
        "index_name = 'semantic-search-openai'\n",
        "\n",
        "\n",
        "if index_name not in pc.list_indexes().names():\n",
        "\n",
        "    pc.create_index(\n",
        "        index_name,\n",
        "        dimension=len(embeddings[qa_pairs[0]]),\n",
        "        metric='dotproduct',\n",
        "        spec=spec\n",
        "    )\n",
        "\n",
        "    while not pc.describe_index(index_name).status['ready']:\n",
        "        time.sleep(1)\n",
        "\n",
        "\n",
        "index = pc.Index(index_name)\n",
        "time.sleep(1)\n",
        "\n",
        "\n",
        "index.describe_index_stats()\n"
      ],
      "metadata": {
        "id": "kWdVQI8CKvDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "VqQZgCeoYRT6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Upsert data to pinecone**"
      ],
      "metadata": {
        "id": "OWBEjLc6YRQU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Set batch size for processing\n",
        "batch_size = 32\n",
        "\n",
        "# Initialize count for creating unique IDs\n",
        "count = 0\n",
        "\n",
        "# Iterate through the dataset in batches\n",
        "for i in tqdm(range(0, len(dataset), batch_size)):\n",
        "    # Set end position of batch\n",
        "    i_end = min(i + batch_size, len(dataset))\n",
        "\n",
        "    # Get batch of question-answer pairs and their IDs\n",
        "    batch_dataset = dataset[i: i_end]\n",
        "    ids_batch = [str(n) for n in range(count, count + len(batch_dataset))]\n",
        "\n",
        "    # Extract embeddings and metadata for the batch\n",
        "    batch_embeddings = [embeddings[qa_pair[0]] for qa_pair in batch_dataset]\n",
        "    batch_metadata = [{'question': qa_pair[0], 'answer': qa_pair[1]} for qa_pair in batch_dataset]\n",
        "\n",
        "    # Upsert batch to Pinecone index\n",
        "    index.upsert(vectors=list(zip(ids_batch, batch_embeddings, batch_metadata)))\n",
        "\n",
        "    # Update count for creating unique IDs\n",
        "    count += len(batch_dataset)\n"
      ],
      "metadata": {
        "id": "RMFCBaRuYWqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_dRWO2NPYYR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Query**"
      ],
      "metadata": {
        "id": "JWooPpLoaYpx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"WHat does Yardstick AI do and where it is headquartered\"\n",
        "\n",
        "xq = client.embeddings.create(input=query, model=MODEL).data[0].embedding\n"
      ],
      "metadata": {
        "id": "WA_U4DLnaaf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = index.query([xq], top_k=2, include_metadata=True)\n"
      ],
      "metadata": {
        "id": "HXhhH_1Vafg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RzgjmL6SaiBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Genreating Respnse**"
      ],
      "metadata": {
        "id": "Ej88Q3HVcy_J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Stack the top 2 matching question-answer pairs together\n",
        "stacked_pairs = \"\\n\\n\".join([f\"Question: {result.metadata['question']}\\nAnswer: {result.metadata['answer']}\" for result in res.results])\n",
        "\n",
        "# Initialize conversation context with the query and stacked pairs\n",
        "\n",
        "\n",
        "conversation_context = f\"User: Hey GPT, this is my query: {query}\\nAI: Based on the following question-answer pairs:\\n{stacked_pairs}\\nUser: give me a short response to this query.\\n\"\n",
        "\n",
        "\n",
        "# Call the OpenAI API to generate a response\n",
        "response = client.Completion.create(\n",
        "    model=MODEL,\n",
        "    prompt=conversation_context,\n",
        "    temperature=0.7,\n",
        "    max_tokens=70\n",
        ")\n",
        "\n",
        "# Print the response\n",
        "print(\"AI Response:\", response.choices[0].text.strip())\n"
      ],
      "metadata": {
        "id": "Jiiz3VGxc2Ji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vMz0CW-_g8Jd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}